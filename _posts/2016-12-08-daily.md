---
title: 每日总结 2016-12-08
author: Li Xiang
date: 2016-12-08
layout: post
tags: [R]
categories: [Daily]
description: ""
---

# Make contrasts in R[^1]

[^1]: [A (sort of) Complete Guide to Contrasts in R](http://rstudio-pubs-static.s3.amazonaws.com/65059_586f394d8eb84f84b1baaf56ffb6b47f.html)

两种应用 contrasts 的方式：
- 添加 contrasts 到 data.frame 中，那么只要用到 data.frame 来构建模型，contrasts 将每次都将被使用。
- 添加 contrasts 到 model 中，那么在检验模型时就会使用到它的 contrasts。

> By default, R uses traditional dummy coding (called “treatment contrasts” in R) for any non- ordered factors, and polynomial trend contrasts for any ordered factors. That works out well if you intend to look at regression coefficients.

R 中默认的 contrasts 为非等级因子使用 treatment contrasts，等级因子使用 polynomial trend contrasts。这在为了考察回归系数时有效。

> Note that traditional dummy coding is fine for regression coefficients, but since traditional dummy codes aren’t orthogonal, it messes things up when you’re just trying to partition variance (i.e. an ANOVA). (Also remember that the default R anova functions use type 1 sums of squares, which is generally not what you want. To get type 3 sums of squares, use the Anova() function from the car package.)

但是，默认的 contrasts 并不适用于需要分解方差时，即方差分析。另外，R 的方差分析函数 `aov` 使用 Type-I 平方和，而一般来说，常用 Type-III 平方和。`car::Anova()` `ez::ezANOVA()` `afex::aov_ez()` 等均支持 Type-III 平方和。

> R is still using traditional dummy coding (treatment contrasts) behind the scenes here, unlike other stats software (like SPSS) that would switch to effects coding for an ANOVA.
>
> For an ANOVA, you should set your factors to use effects coding, rather than relying on the default treatment codes. You can do that with the `contr.sum()` function.
>
> As long as they’re orthogonal, they’ll work fine in an ANOVA.
>
> For ANOVAs, effects coding works great, orthogonal contrast coding works great, and traditional dummy coding not so much.

如果进行方差分析，必须在进行分析之前将 contrasts 给改为 effects coding 或 orthogonal contrast coding。

> Anova() won’t show you the individual contrast results, just the overall effect of each factor. You can see the results of each contrast by using the summary() function on the model object.

使用 `car::Anova()` 并不会显示出每个独立的比较，而仅仅显示出每个因子的总效应。可以把模型对象传入函数 `summary(modobj)`，这样就能显示出每个独立的比较的结果。

> If you use aov() instead of lm() to specify the original model, then you’ll need to add a split argument to the summary() call to see the contrast results.

如果使用 `aov()` 建立模型，而不是 `lm()`，传入 `split` 参数到 `summary()` 才能看到比较的结果。`summary(..., split = list(var = list(...), ...))`。其中，split 参数中也可以不包含所有变量的所有水平。

> You need to be careful, though, because the contrasts() function is a sneaky little bastard, as noted above. To apply contrast weights, you’ll need to give it the inverse of your matrix of weights.

在构建自定义的比较时，需要谨慎，因为 `contrasts()` 函数有一些小技巧，特别时当应用 contrast 权重时，需要对 contasts 矩阵进行求逆运算。

以下为构建自定义比较的步骤：
1. Specfiy the weights for your contrasts (and be sure to check the order of the levels of the factor, so your weights will line up properly). 首先指定 contrasts 的权重。
2. Create a temporary matrix with each contrast as one row. The top row (for the constant) should be 1/j for j groups. 构建临时的矩阵，第一列每个元素为 1/j，如果 j 为水平数。使用 `rbind` 构建临时矩阵。
3. Get the inverse of that temporary matrix. 使用 `solve` 函数对临时矩阵求逆。
4. The first column of the inverse will be all 1’s. Drop that first column. The remaining columns are your contrast matrix. 求逆后的矩阵第一列每一个元素都为1，删除第一列，剩余的列即为最终的 contrast 矩阵。然后就可以在建立模型时传入 contrasts 参数 `contrasts = list(...)`。

> If you specify orthogonal contrasts, the regression coefficients for each contrast should just equal the difference between those group means.

如果指定的 contrasts 为 orthogonal，每个比较的回归系数应该等于比较的组的均值的差值。

> So what happens if you try to run your own contrasts without doing the weird inverse thing? It depends. If your contrasts are orthogonal, then the t-tests and p-values you get for the regression coefficients will all be fine, but your contrast estimates (and corresponding SEs) might not match the difference between group means you expected. If your contrasts are nonorthogonal, then failing to do the weird inverse thing can result in totally garbage estimates and useless t-tests. So you MUST do this inverse thing if you specify nonorthogonal contrasts, but you should probably get in the habbit of doing it anyway for orthogonal ones as well.

不进行矩阵求逆会出现什么结果呢？如果 contrasts 为正交的，那么对回归系数检验的 t 值和 p 值时没有问题的，但是 contrast estimate 以及对应的标准误可能不等于比较的组的均值的差值。如果 contrasts 不是正交的，那么所得到的结果是无效的。所以，最好是对所有 contasts 权重矩阵进行求逆。

> you can get j-1 orthogonal contrasts out of a factor with j levels.
>
> Yep. If you want to save time and only specify the contrast(s) you care about, you can do that, and R will come up with some orthogonal contrasts to fill in the rest. What you won’t be able to do is take the inverse of your contrast weights; you can only take the inverse of a square matrix, and if you have fewer than j-1 contrasts, your temporary matrix won’t be square. But remember: as long as your contrasts are orthogonal, your t-tests will all be fine even if you don’t do the inverse thing. So go ahead and just use the contrasts you want directly with the contrasts() function, and be aware that your contrast estimates may not accurately reflect the differences between group means.

如果进行的比较次数少于 j-1，那么 R 会自动地计算出剩余的正交 contrasts。只不过，此时无法进行矩阵逆运算。不过只要 contrasts 是正交的，那么就不用担心检验的结果。需要考虑的是，contrast estimates 将可能不等于比较的组均值的差值。

> Note that if you add fewer than j-1 contrasts to the contrasts argument in lm(), it will NOT fill out the remaining contrasts for you. Rather, any group differences other than those represented in your contrast will get lumped into the error term!

需要注意，如果 `lm()` 模型中 contrasts 少于 j-1 次，没有反映在 contrasts 中的组差异将被纳入到误差项中。

**问题：什么是正交的 contrasts？如何建立正交 contrasts？**

> **Orthogonal contrasts** are a set of contrasts in which, for any distinct pair, **the sum of the cross-products of the coefficients is zero** (assume sample sizes are equal). Although there are potentially infinite sets of orthogonal contrasts, within any given set there will always be a maximum of exactly k – 1 possible orthogonal contrasts (where k is the number of group means available).

> There are only k-1 orthogonal comparisons, where k is the number of factor levels.
> Comparisons/contrasts orthogonal to each other are statistically independent.
> Which of the possible comparisons should we conduct? Well, this very much depends on our hypothesis we have in mind.

> We need to specify a contrast matrix, showing which comparisons we want to make. A contrast matrix consists of so-called contrast coefficients that (in the end) all have to sum to zero. This means, those things we want to compare have to get the opposite sign (e.g. +1 and –1), while those things we don ́t want to compare will receive a value of zero.

> Orthogonal contrasts are planned, a priori tests that partition the experimental variance cleanly. They are a powerful tool for analyzing data, but they are not appropriate for all experiments. Less restrictive comparisons among treatment means can be performed using various means separation tests, or multiple comparison tests.

- 两个比较的向量点对点相乘的和等于0的比较为正交比较。
- 水平数为 k 的因子，最多有 k-1 次正交比较。
- 正交比较之间在统计上相对独立。
- 进行什么样的比较与研究假设相关。
- 在一个比较中，相互比较的水平之间的比较矩阵中对应的数值和为0，两者符号相反，其它水平数值为0。

**问题：R 有哪些内置的构建 contrasts 的函数？**

`contr.treatment()`
`contr.helmert()`
`contr.poly()`
`contr.sum()`
`contr.SAS`

-------------------------------------------------------------------------------

# 杂项

> calculating post-hoc power are flawed and can produce misleading conclusions. Once a confidence interval has been computed, there is no additional information that a post hoc power calculation can provide. (Hoenig & Heisey 2001)

# 翻译

> We have empirically assessed the distribution of published effect sizes and estimated power by extracting more than 100,000 statistical records from about 10,000 cognitive neuroscience and psychology papers published during the past 5 years. The reported median effect size was d=0.93 (inter-quartile range: 0.64-1.46) for nominally statistically significant results and d=0.24 (0.11-0.42) for non-significant results. Median power to detect small, medium and large effects was 0.12, 0.44 and 0.73, reflecting no improvement through the past half-century. Power was lowest for cognitive neuroscience journals. 14% of papers reported some statistically significant results, although the respective F statistic and degrees of freedom proved that these were non-significant; p value errors positively correlated with journal impact factors. False report probability is likely to exceed 50% for the whole literature. In light of our findings the recently reported low replication success in psychology is realistic and worse performance may be expected for cognitive neuroscience.^[2][]

我们从10,000篇近五年的认知神经科学和心理学已发表的期刊论文中提取了100,000份统计学记录，评估了发表的效应量 (effect sizes) 和估计的统计检验力 (power) 的统计分布。对于名义上达到统计显著性的结果中报告的效应量中位数为 d=0.93（四分位数范围为：0.64-1.46），而对于未达到统计显著性的结果，报告效应量中位数为 d=0.24 (四分位数范围：0.11-0.42)。检测到较弱，中等、较强的效应的统计检验力中位数分别为0.12，0.44，以及0.73。这表面在这几个领域内统计检验力在近半个世纪没有任何提高。其中，认知神经科学期刊论文的统计检验力最低（研究者考察了医学、心理学和认知神经科学）。14% 的论文报告了一些统计上显著的结果，然而这些结果中对应的 F 统计量和自由度均证明了这些结果并未达到显著。（有意思的是）p值的错误报告与期刊的影响因子呈正相关关系。在所有文献范围内，错误报告概率（False report probability）超过了50%。我们的结果提示，近来报告的心理学领域的低重复率问题是确实存在的，而且在认知神经科学领域可能预示着更严重的低重复率问题。

[2]: Szucs, D., & Ioannidis, J. P. (2016). Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature. bioRxiv, 071530.
